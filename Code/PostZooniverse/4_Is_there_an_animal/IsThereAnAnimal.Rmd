---
title: "Is there an animal?"
output: html_notebook
---

R code to extract, flatten and analyze Maggie's data from the "Is there an animal" workflow to find out how many misfires, etc.

Set things up:

```{r, message=FALSE, echo=FALSE}
rm(list = ls())
library(here)
library(tidyverse)
library(tidyjson)#may get error; if so, load from github
library(jsonlite)
library(magrittr) #allows piping beyond tidyverse
library(dplyr)
library(stringr)
library(tidyr)
library(lubridate)
library(rstudioapi)

myFunctions<-list.files(here("Code", "Functions"), pattern = "R") 
#points to files that need to be sourced

sapply(here("Code", "Functions", myFunctions), source) #sources all of the functions in the Functions folder.
```
###Step 1. Choose the classification file to work with.
We have multiple classification files. The choose_file_isol asks the user for input so that they can select the classification file to work with. The classification file should be on the t://drive in Bart_s04/Research_group/NoCoWild/Data/classification_files.

Try with the `choose_file_isolate_workflow` function

```{r}
DF<-choose_file_isolate_workflow()
data<-DF[[1]]
filename<-"flat_is_there_animal"
```
Now isolate to just the classification dates that match Maggie's project:

So here we can subset to the start date you want. Note that the start date is not the date the pictures were taken but is the date the classifications were made.
```{r}
data<-narrow_to_date(data)
```

### Step 2. Parse the annotations column
We now flatten the Annotations column by calling the  `flatten_annotations` function. But it may need modification for this type of workflow. Let's start by viewing some annotations

```{r}
View_annotations(data,2)
```
```{r}
flat_file<-flatten_is_there_animal_annotations(data) #this is slow; could we write faster code?  A problem for another day.
```

### Step 3. Parse the subjects column

Now we can parse the subject data.

```{r}
subjects<-flatten_subjects(data)
```

###Step 4. Merge the annotations and subjects data
Now that we have flattened both the annotations and subject_data columns, we would like to generate one large data frame with all of the data to export and analyze (using different R scripts!).  To do so, we need to join the two data frames.  Joining will **only work** if you have a column, named identically in both data frames, on which the join will work.

The join itself is pretty easy:
```{r}
Flattened<-left_join(flat_file, subjects, by='classification_id')
```
Now move subject_ids column to left most position
```{r}
Flattened<-Flattened %>% relocate(subject_ids)
```


Now extract just Maggie's data

```{r}
# Flattened<-Flattened %>% filter(Treatment == "Snap" | Treatment == "Snapshot" | Treatment == "AIM")
```

Now clean up some of the subjects columns
```{r}
#columns to delete
Dump<-c( "round", "Img1", "Img2", "Img3", "CamNum", "SD_card_num", "Event", "Batch", "Round2","CamNum2", "SDCard2", "For_type", "For_name", "SDCard3")
Flattened<-Flattened %>% select(!Dump)
#now fix column names
fix<-colnames(Flattened)
fix
fix[14:16]<-c("Img1", "Img2", "Img3")
fix[19]<-"Event"
fix[21]<-"CamNum"
fix
colnames(Flattened)<-fix
```

Now Save our result! This will go in the flattened folder within the PostZooniverse outputs.
```{r}
output<-here("Output", "PostZooniverse", "Flattened")

#myFile<-str_remove(filename, ".csv") #drop the .csv temporarily

write.csv(Flattened,  paste0(output, "/",filename,"-", Sys.Date(), ".csv"))

```


